{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>PRI 2022: first project delivery</H3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GROUP X**\n",
    "- name, number\n",
    "- name, number\n",
    "- name, number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Part I: demo of facilities</H3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A) Indexing facilities**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A.1 Preprocessing options: statistics*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A.2 Indexing statistics*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B) Ranking facilities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: parsing empty text\n"
     ]
    }
   ],
   "source": [
    "# load files\n",
    "from src.mainFunctions.ranking import ranking\n",
    "from operator import attrgetter\n",
    "from src.helper.documentHelper import read_files\n",
    "from src.mainFunctions.indexing import indexing\n",
    "order_ranked = True\n",
    "text_processing = True\n",
    "documents = read_files(text_processing, [\"business\"])\n",
    "\n",
    "corpus_index = indexing(list(map(attrgetter('text_terms'), documents)))\n",
    "corpus_idfs: {str: float} = {}\n",
    "\n",
    "for v in corpus_index:\n",
    "    corpus_idfs[v] = corpus_index[v].inverted_document_frequency\n",
    "\n",
    "document = documents[0]\n",
    "\n",
    "summary1 = ranking(document, 7, None, order_ranked, corpus_idfs, {\"rank_option\": \"tf\", \"mmr\": True})\n",
    "summary2 = ranking(document, 3, None, order_ranked, corpus_idfs, {\"rank_option\": \"tf-idf\", \"mmr\": False})\n",
    "summary3 = ranking(document, 3, None, order_ranked, corpus_idfs, {\"rank_option\": \"bm25\", \"mmr\": False})\n",
    "summary4 = ranking(document, 3, None, order_ranked, corpus_idfs, {\"rank_option\": \"rrf\", \"mmr\": False})\n",
    "summary5 = ranking(document, 3, None, order_ranked, corpus_idfs, {\"rank_option\": \"tf-idf\", \"mmr\": True})\n",
    "\n",
    "document.summary = summary5\n",
    "\n",
    "document_sentences = document.text_sentences\n",
    "summary_sentences = document.summary\n",
    "reference_summary_sentences = document.referenceSummary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*B.1 Summarization solution: results for a given document*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*B.2 Classic IR models: differences*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*B.3 Reciprocal rank funsion*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*B.4 Maximal Marginal Relevance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C) Sentence higlighting facilities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D) Evaluation facilities**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*D.1 Evaluation options*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*D.2 Comparison of settings (IR models, preprocessing)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Part II: questions materials (optional)</H3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)** Corpus and summary description. Distribution of informative terms before and after text processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: parsing empty text\n",
      "UK economy facing 'major risks'\n",
      "\n",
      "The UK manufacturing sector will continue to face \"serious challenges\" over the next two years, the British Chamber of Commerce (BCC) has said.\n",
      "\n",
      "The group's quarterly survey of companies found exports had picked up in the last three months of 2004 to their best levels in eight years. The rise came despite exchange rates being cited as a major concern. However, the BCC found the whole UK economy still faced \"major risks\" and warned that growth is set to slow. It recently forecast economic growth will slow from more than 3% in 2004 to a little below 2.5% in both 2005 and 2006.\n",
      "\n",
      "Manufacturers' domestic sales growth fell back slightly in the quarter, the survey of 5,196 firms found. Employment in manufacturing also fell and job expectations were at their lowest level for a year.\n",
      "\n",
      "\"Despite some positive news for the export sector, there are worrying signs for manufacturing,\" the BCC said. \"These results reinforce our concern over the sector's persistent inability to sustain recovery.\" The outlook for the service sector was \"uncertain\" despite an increase in exports and orders over the quarter, the BCC noted.\n",
      "\n",
      "The BCC found confidence increased in the quarter across both the manufacturing and service sectors although overall it failed to reach the levels at the start of 2004. The reduced threat of interest rate increases had contributed to improved confidence, it said. The Bank of England raised interest rates five times between November 2003 and August last year. But rates have been kept on hold since then amid signs of falling consumer confidence and a slowdown in output. \"The pressure on costs and margins, the relentless increase in regulations, and the threat of higher taxes remain serious problems,\" BCC director general David Frost said. \"While consumer spending is set to decelerate significantly over the next 12-18 months, it is unlikely that investment and exports will rise sufficiently strongly to pick up the slack.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#code, statistics and/or charts here\n",
    "\n",
    "from src.helper.documentHelper import read_files\n",
    "\n",
    "\n",
    "documents_no_preprocessing = read_files(False)\n",
    "documents_preprocessing = read_files(True)\n",
    "\n",
    "print(documents_preprocessing[0].text)  #Test\n",
    "\n",
    "# Calculate distribution of informative termsstics and/or charts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** Summarization performance for the overall and category-conditional corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code, statistics and/or charts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'write_to_csv' from 'src.helper.helper' (D:\\STUDIA\\Tecnico\\RGI_proj\\RGIProject\\src\\helper\\helper.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [6], line 16\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmainFunctions\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mevaluation\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m calculate_precision_recall\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmainFunctions\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mevaluation\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m calculate_fbeta_measure\n\u001B[1;32m---> 16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mhelper\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mhelper\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m write_to_csv\n\u001B[0;32m     18\u001B[0m order_ranked \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     19\u001B[0m text_processing \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'write_to_csv' from 'src.helper.helper' (D:\\STUDIA\\Tecnico\\RGI_proj\\RGIProject\\src\\helper\\helper.py)"
     ]
    }
   ],
   "source": [
    "#question 2\n",
    "from operator import attrgetter\n",
    "\n",
    "from src.mainFunctions.indexing import indexing\n",
    "from src.helper.documentHelper import read_files\n",
    "from src.mainFunctions.ranking import ranking\n",
    "\n",
    "from src.mainFunctions.evaluation import calculate_true_pos\n",
    "from src.mainFunctions.evaluation import get_MAP_avg_by_cat_and_standard_deviation\n",
    "from src.mainFunctions.evaluation import draw_MAP_chart\n",
    "from src.mainFunctions.evaluation import calculate_precision_recall_tables_and_MAP_param\n",
    "from src.mainFunctions.evaluation import draw_precision_recall_curve\n",
    "from src.mainFunctions.evaluation import calculate_precision_recall\n",
    "from src.mainFunctions.evaluation import calculate_fbeta_measure\n",
    "\n",
    "from src.helper.helper import write_to_csv\n",
    "\n",
    "order_ranked = True\n",
    "text_processing = True\n",
    "documents = read_files(text_processing)\n",
    "index = indexing(list(map(attrgetter('text_terms'), documents)))\n",
    "corpus_idfs: {str: float} = {}\n",
    "for v in index:\n",
    "    corpus_idfs[v] = index[v].inverted_document_frequency\n",
    "fbeta_list_tf = []\n",
    "# MAP_avg_by_cat_and_standard_deviation, interpolated recall-and-precision curve for doc 2 - tf\n",
    "for document in documents:\n",
    "    document.summary = ranking(document, 8, 1010, order_ranked, corpus_idfs, {\"rank_option\": \"tf\", \"mmr\": False})\n",
    "    true_pos = calculate_true_pos(document)\n",
    "    precision_recall_tuple = calculate_precision_recall(document.referenceSummary, document.summary, true_pos)\n",
    "    fbeta_list_tf.append(calculate_fbeta_measure(precision_recall_tuple[0], precision_recall_tuple[1]))\n",
    "    precision_recall_tuple_table = calculate_precision_recall_tables_and_MAP_param(document.summary,\n",
    "                                                                             true_pos)\n",
    "    if document.id == 2:\n",
    "        draw_precision_recall_curve(precision_recall_tuple_table)\n",
    "\n",
    "avg_fbeta_tf = sum(fbeta_list_tf) / len(fbeta_list_tf)\n",
    "print(avg_fbeta_tf)\n",
    "\n",
    "business_docs = list(filter(lambda d: d.category == \"business\", documents))\n",
    "business = get_MAP_avg_by_cat_and_standard_deviation(business_docs)\n",
    "\n",
    "entertainment_docs = list(filter(lambda d: d.category == \"entertainment\", documents))\n",
    "entertainment = get_MAP_avg_by_cat_and_standard_deviation(entertainment_docs)\n",
    "\n",
    "politics_docs = list(filter(lambda d: d.category == \"politics\", documents))\n",
    "politics = get_MAP_avg_by_cat_and_standard_deviation(politics_docs)\n",
    "\n",
    "sport_docs = list(filter(lambda d: d.category == \"sport\", documents))\n",
    "sport = get_MAP_avg_by_cat_and_standard_deviation(sport_docs)\n",
    "\n",
    "tech_docs = list(filter(lambda d: d.category == \"tech\", documents))\n",
    "tech = get_MAP_avg_by_cat_and_standard_deviation(tech_docs)\n",
    "\n",
    "draw_MAP_chart(business, entertainment, politics, sport, tech)\n",
    "\n",
    "fbeta_list_tf_idf = []\n",
    "# MAP_avg_by_cat_and_standard_deviation, interpolated recall-and-precision curve for doc 2 - tf-idf\n",
    "for document in documents:\n",
    "    document.summary = ranking(document, 8, 1010, order_ranked, corpus_idfs, {\"rank_option\": \"tf-idf\", \"mmr\": False})\n",
    "    true_pos = calculate_true_pos(document)\n",
    "    precision_recall_tuple = calculate_precision_recall(document.referenceSummary, document.summary, true_pos)\n",
    "    fbeta_list_tf_idf.append(calculate_fbeta_measure(precision_recall_tuple[0], precision_recall_tuple[1]))\n",
    "    precision_recall_tuple_table = calculate_precision_recall_tables_and_MAP_param(document.summary,\n",
    "                                                                                   true_pos)\n",
    "    if document.id == 2:\n",
    "        draw_precision_recall_curve(precision_recall_tuple_table)\n",
    "\n",
    "avg_fbeta_tf_idf = sum(fbeta_list_tf_idf) / len(fbeta_list_tf_idf)\n",
    "print(avg_fbeta_tf_idf)\n",
    "\n",
    "business_docs = list(filter(lambda d: d.category == \"business\", documents))\n",
    "business = get_MAP_avg_by_cat_and_standard_deviation(business_docs)\n",
    "\n",
    "entertainment_docs = list(filter(lambda d: d.category == \"entertainment\", documents))\n",
    "entertainment = get_MAP_avg_by_cat_and_standard_deviation(entertainment_docs)\n",
    "\n",
    "politics_docs = list(filter(lambda d: d.category == \"politics\", documents))\n",
    "politics = get_MAP_avg_by_cat_and_standard_deviation(politics_docs)\n",
    "\n",
    "sport_docs = list(filter(lambda d: d.category == \"sport\", documents))\n",
    "sport = get_MAP_avg_by_cat_and_standard_deviation(sport_docs)\n",
    "\n",
    "tech_docs = list(filter(lambda d: d.category == \"tech\", documents))\n",
    "tech = get_MAP_avg_by_cat_and_standard_deviation(tech_docs)\n",
    "\n",
    "draw_MAP_chart(business, entertainment, politics, sport, tech)\n",
    "\n",
    "fbeta_list_bm25 = []\n",
    "# MAP_avg_by_cat_and_standard_deviation, interpolated recall-and-precision curve for doc 2 - bm25\n",
    "for document in documents:\n",
    "    document.summary = ranking(document, 8, 1010, order_ranked, corpus_idfs, {\"rank_option\": \"bm25\", \"mmr\": False})\n",
    "    true_pos = calculate_true_pos(document)\n",
    "    precision_recall_tuple = calculate_precision_recall(document.referenceSummary, document.summary, true_pos)\n",
    "    fbeta_list_bm25.append(calculate_fbeta_measure(precision_recall_tuple[0], precision_recall_tuple[1]))\n",
    "    precision_recall_tuple_table = calculate_precision_recall_tables_and_MAP_param(document.summary,\n",
    "                                                                                   true_pos)\n",
    "    if document.id == 2:\n",
    "        draw_precision_recall_curve(precision_recall_tuple_table)\n",
    "\n",
    "avg_fbeta_bm25 = sum(fbeta_list_bm25) / len(fbeta_list_bm25)\n",
    "print(avg_fbeta_bm25)\n",
    "\n",
    "business_docs = list(filter(lambda d: d.category == \"business\", documents))\n",
    "business = get_MAP_avg_by_cat_and_standard_deviation(business_docs)\n",
    "\n",
    "entertainment_docs = list(filter(lambda d: d.category == \"entertainment\", documents))\n",
    "entertainment = get_MAP_avg_by_cat_and_standard_deviation(entertainment_docs)\n",
    "\n",
    "politics_docs = list(filter(lambda d: d.category == \"politics\", documents))\n",
    "politics = get_MAP_avg_by_cat_and_standard_deviation(politics_docs)\n",
    "\n",
    "sport_docs = list(filter(lambda d: d.category == \"sport\", documents))\n",
    "sport = get_MAP_avg_by_cat_and_standard_deviation(sport_docs)\n",
    "\n",
    "tech_docs = list(filter(lambda d: d.category == \"tech\", documents))\n",
    "tech = get_MAP_avg_by_cat_and_standard_deviation(tech_docs)\n",
    "\n",
    "draw_MAP_chart(business, entertainment, politics, sport, tech)\n",
    "\n",
    "fbeta_header = ['all_docs_tf', 'all_docs_tf_idf', 'all_docs_bm25']\n",
    "fbeta_data = [avg_fbeta_tf, avg_fbeta_tf_idf, avg_fbeta_bm25]\n",
    "write_to_csv('fbeta.csv', fbeta_header, [fbeta_data])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'write_to_csv' from 'src.helper.helper' (D:\\STUDIA\\Tecnico\\RGI_proj\\RGIProject\\src\\helper\\helper.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [7], line 16\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmainFunctions\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mevaluation\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m calculate_precision_recall\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmainFunctions\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mevaluation\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m calculate_fbeta_measure\n\u001B[1;32m---> 16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mhelper\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mhelper\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m write_to_csv\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcalculate_avg_precision_recall_for_category\u001B[39m(category_docs, p, l):\n\u001B[0;32m     19\u001B[0m     precision_table \u001B[38;5;241m=\u001B[39m []\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'write_to_csv' from 'src.helper.helper' (D:\\STUDIA\\Tecnico\\RGI_proj\\RGIProject\\src\\helper\\helper.py)"
     ]
    }
   ],
   "source": [
    "#question 4\n",
    "from operator import attrgetter\n",
    "\n",
    "from src.mainFunctions.indexing import indexing\n",
    "from src.helper.documentHelper import read_files\n",
    "from src.mainFunctions.ranking import ranking\n",
    "\n",
    "from src.mainFunctions.evaluation import calculate_true_pos\n",
    "from src.mainFunctions.evaluation import get_MAP_avg_by_cat_and_standard_deviation\n",
    "from src.mainFunctions.evaluation import draw_MAP_chart\n",
    "from src.mainFunctions.evaluation import calculate_precision_recall_tables_and_MAP_param\n",
    "from src.mainFunctions.evaluation import draw_precision_recall_curve\n",
    "from src.mainFunctions.evaluation import calculate_precision_recall\n",
    "from src.mainFunctions.evaluation import calculate_fbeta_measure\n",
    "\n",
    "from src.helper.helper import write_to_csv\n",
    "\n",
    "def calculate_avg_precision_recall_for_category(category_docs, p, l):\n",
    "    precision_table = []\n",
    "    recall_table = []\n",
    "    for document in category_docs:\n",
    "        document.summary = ranking(document, p, l, order_ranked, corpus_idfs,\n",
    "                                   {\"rank_option\": \"tf-idf\", \"mmr\": False})\n",
    "        true_pos = calculate_true_pos(document)\n",
    "        precision_recall_tuple = calculate_precision_recall(document.referenceSummary, document.summary, true_pos)\n",
    "        precision_table.append(precision_recall_tuple[0])\n",
    "        recall_table.append(precision_recall_tuple[1])\n",
    "\n",
    "    precision_avg = sum(precision_table) / len(recall_table)\n",
    "    recall_avg = sum(recall_table) / len(recall_table)\n",
    "    return precision_avg, recall_avg\n",
    "\n",
    "\n",
    "order_ranked = True\n",
    "text_processing = True\n",
    "documents = read_files(text_processing)\n",
    "index = indexing(list(map(attrgetter('text_terms'), documents)))\n",
    "corpus_idfs: {str: float} = {}\n",
    "for v in index:\n",
    "    corpus_idfs[v] = index[v].inverted_document_frequency\n",
    "\n",
    "row1 = [6, 800]\n",
    "row2 = [6, 1010]\n",
    "row3 = [6, 1200]\n",
    "row4 = [8, 800]\n",
    "row5 = [8, 1010]\n",
    "row6 = [8, 1200]\n",
    "row7 = [10, 800]\n",
    "row8 = [10, 1010]\n",
    "row9 = [10, 1200]\n",
    "\n",
    "\n",
    "all_documents_6_800 = calculate_avg_precision_recall_for_category(documents, 6, 800)\n",
    "precision_avg_6_800 = all_documents_6_800[0]\n",
    "recall_avg_6_800 = all_documents_6_800[1]\n",
    "row1.append(precision_avg_6_800)\n",
    "row1.append(recall_avg_6_800)\n",
    "\n",
    "all_documents_6_1010 = calculate_avg_precision_recall_for_category(documents, 6, 1010)\n",
    "precision_avg_6_1010 = all_documents_6_1010[0]\n",
    "recall_avg_6_1010 = all_documents_6_1010[1]\n",
    "row2.append(precision_avg_6_1010)\n",
    "row2.append(recall_avg_6_1010)\n",
    "\n",
    "all_documents_6_1200 = calculate_avg_precision_recall_for_category(documents, 6, 1200)\n",
    "precision_avg_6_1200 = all_documents_6_1200[0]\n",
    "recall_avg_6_1200 = all_documents_6_1200[1]\n",
    "row3.append(precision_avg_6_1200)\n",
    "row3.append(recall_avg_6_1200)\n",
    "\n",
    "all_documents_8_800 = calculate_avg_precision_recall_for_category(documents, 8, 800)\n",
    "precision_avg_8_800 = all_documents_8_800[0]\n",
    "recall_avg_8_800 = all_documents_8_800[1]\n",
    "row4.append(precision_avg_8_800)\n",
    "row4.append(recall_avg_8_800)\n",
    "\n",
    "all_documents_8_1010 = calculate_avg_precision_recall_for_category(documents, 8, 1010)\n",
    "precision_avg_8_1010 = all_documents_8_1010[0]\n",
    "recall_avg_8_1010 = all_documents_8_1010[1]\n",
    "row5.append(precision_avg_8_1010)\n",
    "row5.append(recall_avg_8_1010)\n",
    "\n",
    "all_documents_8_1200 = calculate_avg_precision_recall_for_category(documents, 8, 1200)\n",
    "precision_avg_8_1200 = all_documents_8_1200[0]\n",
    "recall_avg_8_1200 = all_documents_8_1200[1]\n",
    "row6.append(precision_avg_8_1200)\n",
    "row6.append(recall_avg_8_1200)\n",
    "\n",
    "all_documents_10_800 = calculate_avg_precision_recall_for_category(documents, 10, 800)\n",
    "precision_avg_10_800 = all_documents_10_800[0]\n",
    "recall_avg_10_800 = all_documents_10_800[1]\n",
    "row7.append(precision_avg_10_800)\n",
    "row7.append(recall_avg_10_800)\n",
    "\n",
    "all_documents_10_1010 = calculate_avg_precision_recall_for_category(documents, 10, 1010)\n",
    "precision_avg_10_1010 = all_documents_10_1010[0]\n",
    "recall_avg_10_1010 = all_documents_10_1010[1]\n",
    "row8.append(precision_avg_10_1010)\n",
    "row8.append(recall_avg_10_1010)\n",
    "\n",
    "all_documents_10_1200 = calculate_avg_precision_recall_for_category(documents, 10, 1200)\n",
    "precision_avg_10_1200 = all_documents_10_1200[0]\n",
    "recall_avg_10_1200 = all_documents_10_1200[1]\n",
    "row9.append(precision_avg_10_1200)\n",
    "row9.append(recall_avg_10_1200)\n",
    "\n",
    "business_docs = list(filter(lambda d: d.category == \"business\", documents))\n",
    "\n",
    "business_6_800 = calculate_avg_precision_recall_for_category(business_docs, 6, 800)\n",
    "business_precision_avg_6_800 = business_6_800[0]\n",
    "business_recall_avg_6_800 = business_6_800[1]\n",
    "row1.append(business_precision_avg_6_800)\n",
    "row1.append(business_precision_avg_6_800)\n",
    "\n",
    "business_6_1010 = calculate_avg_precision_recall_for_category(business_docs, 6, 1010)\n",
    "business_precision_avg_6_1010 = business_6_1010[0]\n",
    "business_recall_avg_6_1010 = business_6_1010[1]\n",
    "row2.append(business_precision_avg_6_1010)\n",
    "row2.append(business_recall_avg_6_1010)\n",
    "\n",
    "business_6_1200 = calculate_avg_precision_recall_for_category(business_docs, 6, 1200)\n",
    "business_precision_avg_6_1200 = business_6_1200[0]\n",
    "business_recall_avg_6_1200 = business_6_1200[1]\n",
    "row3.append(business_precision_avg_6_1200)\n",
    "row3.append(business_recall_avg_6_1200)\n",
    "\n",
    "business_8_800 = calculate_avg_precision_recall_for_category(business_docs, 8, 800)\n",
    "business_precision_avg_8_800 = business_8_800[0]\n",
    "business_recall_avg_8_800 = business_8_800[1]\n",
    "row4.append(business_precision_avg_8_800)\n",
    "row4.append(business_recall_avg_8_800)\n",
    "\n",
    "business_8_1010 = calculate_avg_precision_recall_for_category(business_docs, 8, 1010)\n",
    "business_precision_avg_8_1010 = business_8_1010[0]\n",
    "business_recall_avg_8_1010 = business_8_1010[1]\n",
    "row5.append(business_precision_avg_8_1010)\n",
    "row5.append(business_recall_avg_8_1010)\n",
    "\n",
    "business_8_1200 = calculate_avg_precision_recall_for_category(business_docs, 8, 1200)\n",
    "business_precision_avg_8_1200 = business_8_1200[0]\n",
    "business_recall_avg_8_1200 = business_8_1200[1]\n",
    "row6.append(business_precision_avg_8_1200)\n",
    "row6.append(business_recall_avg_8_1200)\n",
    "\n",
    "business_10_800 = calculate_avg_precision_recall_for_category(business_docs, 10, 800)\n",
    "business_precision_avg_10_800 = business_10_800[0]\n",
    "business_recall_avg_10_800 = business_10_800[1]\n",
    "row7.append(business_precision_avg_10_800)\n",
    "row7.append(business_recall_avg_10_800)\n",
    "\n",
    "business_10_1010 = calculate_avg_precision_recall_for_category(business_docs, 10, 1010)\n",
    "business_precision_avg_10_1010 = business_10_1010[0]\n",
    "business_recall_avg_10_1010 = business_10_1010[1]\n",
    "row8.append(business_precision_avg_10_1010)\n",
    "row8.append(business_recall_avg_10_1010)\n",
    "\n",
    "business_10_1200 = calculate_avg_precision_recall_for_category(business_docs, 10, 1200)\n",
    "business_precision_avg_10_1200 = business_10_1200[0]\n",
    "business_recall_avg_10_1200 = business_10_1200[1]\n",
    "row9.append(business_precision_avg_10_1200)\n",
    "row9.append(business_recall_avg_10_1200)\n",
    "\n",
    "entertainment_docs = list(filter(lambda d: d.category == \"entertainment\", documents))\n",
    "\n",
    "entertainment_6_800 = calculate_avg_precision_recall_for_category(entertainment_docs, 6, 800)\n",
    "entertainment_precision_avg_6_800 = entertainment_6_800[0]\n",
    "entertainment_recall_avg_6_800 = entertainment_6_800[1]\n",
    "row1.append(entertainment_precision_avg_6_800)\n",
    "row1.append(entertainment_precision_avg_6_800)\n",
    "\n",
    "entertainment_6_1010 = calculate_avg_precision_recall_for_category(entertainment_docs, 6, 1010)\n",
    "entertainment_precision_avg_6_1010 = entertainment_6_1010[0]\n",
    "entertainment_recall_avg_6_1010 = entertainment_6_1010[1]\n",
    "row2.append(entertainment_precision_avg_6_1010)\n",
    "row2.append(entertainment_recall_avg_6_1010)\n",
    "\n",
    "entertainment_6_1200 = calculate_avg_precision_recall_for_category(entertainment_docs, 6, 1200)\n",
    "entertainment_precision_avg_6_1200 = entertainment_6_1200[0]\n",
    "entertainment_recall_avg_6_1200 = entertainment_6_1200[1]\n",
    "row3.append(entertainment_precision_avg_6_1200)\n",
    "row3.append(entertainment_recall_avg_6_1200)\n",
    "\n",
    "entertainment_8_800 = calculate_avg_precision_recall_for_category(entertainment_docs, 8, 800)\n",
    "entertainment_precision_avg_8_800 = entertainment_8_800[0]\n",
    "entertainment_recall_avg_8_800 = entertainment_8_800[1]\n",
    "row4.append(entertainment_precision_avg_8_800)\n",
    "row4.append(entertainment_recall_avg_8_800)\n",
    "\n",
    "entertainment_8_1010 = calculate_avg_precision_recall_for_category(entertainment_docs, 8, 1010)\n",
    "entertainment_precision_avg_8_1010 = entertainment_8_1010[0]\n",
    "entertainment_recall_avg_8_1010 = entertainment_8_1010[1]\n",
    "row5.append(entertainment_precision_avg_8_1010)\n",
    "row5.append(entertainment_recall_avg_8_1010)\n",
    "\n",
    "entertainment_8_1200 = calculate_avg_precision_recall_for_category(entertainment_docs, 8, 1200)\n",
    "entertainment_precision_avg_8_1200 = entertainment_8_1200[0]\n",
    "entertainment_recall_avg_8_1200 = entertainment_8_1200[1]\n",
    "row6.append(entertainment_precision_avg_8_1200)\n",
    "row6.append(entertainment_recall_avg_8_1200)\n",
    "\n",
    "entertainment_10_800 = calculate_avg_precision_recall_for_category(entertainment_docs, 10, 800)\n",
    "entertainment_precision_avg_10_800 = entertainment_10_800[0]\n",
    "entertainment_recall_avg_10_800 = entertainment_10_800[1]\n",
    "row7.append(entertainment_precision_avg_10_800)\n",
    "row7.append(entertainment_recall_avg_10_800)\n",
    "\n",
    "entertainment_10_1010 = calculate_avg_precision_recall_for_category(entertainment_docs, 10, 1010)\n",
    "entertainment_precision_avg_10_1010 = entertainment_10_1010[0]\n",
    "entertainment_recall_avg_10_1010 = entertainment_10_1010[1]\n",
    "row8.append(entertainment_precision_avg_10_1010)\n",
    "row8.append(entertainment_recall_avg_10_1010)\n",
    "\n",
    "entertainment_10_1200 = calculate_avg_precision_recall_for_category(entertainment_docs, 10, 1200)\n",
    "entertainment_precision_avg_10_1200 = entertainment_10_1200[0]\n",
    "entertainment_recall_avg_10_1200 = entertainment_10_1200[1]\n",
    "row9.append(entertainment_precision_avg_10_1200)\n",
    "row9.append(entertainment_recall_avg_10_1200)\n",
    "\n",
    "politics_docs = list(filter(lambda d: d.category == \"politics\", documents))\n",
    "politics_6_800 = calculate_avg_precision_recall_for_category(politics_docs, 6, 800)\n",
    "politics_precision_avg_6_800 = politics_6_800[0]\n",
    "politics_recall_avg_6_800 = politics_6_800[1]\n",
    "row1.append(politics_precision_avg_6_800)\n",
    "row1.append(politics_precision_avg_6_800)\n",
    "\n",
    "politics_6_1010 = calculate_avg_precision_recall_for_category(politics_docs, 6, 1010)\n",
    "politics_precision_avg_6_1010 = politics_6_1010[0]\n",
    "politics_recall_avg_6_1010 = politics_6_1010[1]\n",
    "row2.append(politics_precision_avg_6_1010)\n",
    "row2.append(politics_recall_avg_6_1010)\n",
    "\n",
    "politics_6_1200 = calculate_avg_precision_recall_for_category(politics_docs, 6, 1200)\n",
    "politics_precision_avg_6_1200 = politics_6_1200[0]\n",
    "politics_recall_avg_6_1200 = politics_6_1200[1]\n",
    "row3.append(politics_precision_avg_6_1200)\n",
    "row3.append(politics_recall_avg_6_1200)\n",
    "\n",
    "politics_8_800 = calculate_avg_precision_recall_for_category(politics_docs, 8, 800)\n",
    "politics_precision_avg_8_800 = politics_8_800[0]\n",
    "politics_recall_avg_8_800 = politics_8_800[1]\n",
    "row4.append(politics_precision_avg_8_800)\n",
    "row4.append(politics_recall_avg_8_800)\n",
    "\n",
    "politics_8_1010 = calculate_avg_precision_recall_for_category(politics_docs, 8, 1010)\n",
    "politics_precision_avg_8_1010 = politics_8_1010[0]\n",
    "politics_recall_avg_8_1010 = politics_8_1010[1]\n",
    "row5.append(politics_precision_avg_8_1010)\n",
    "row5.append(politics_recall_avg_8_1010)\n",
    "\n",
    "politics_8_1200 = calculate_avg_precision_recall_for_category(politics_docs, 8, 1200)\n",
    "politics_precision_avg_8_1200 = politics_8_1200[0]\n",
    "politics_recall_avg_8_1200 = politics_8_1200[1]\n",
    "row6.append(politics_precision_avg_8_1200)\n",
    "row6.append(politics_recall_avg_8_1200)\n",
    "\n",
    "politics_10_800 = calculate_avg_precision_recall_for_category(politics_docs, 10, 800)\n",
    "politics_precision_avg_10_800 = politics_10_800[0]\n",
    "politics_recall_avg_10_800 = politics_10_800[1]\n",
    "row7.append(politics_precision_avg_10_800)\n",
    "row7.append(politics_recall_avg_10_800)\n",
    "\n",
    "politics_10_1010 = calculate_avg_precision_recall_for_category(politics_docs, 10, 1010)\n",
    "politics_precision_avg_10_1010 = politics_10_1010[0]\n",
    "politics_recall_avg_10_1010 = politics_10_1010[1]\n",
    "row8.append(politics_precision_avg_10_1010)\n",
    "row8.append(politics_recall_avg_10_1010)\n",
    "\n",
    "politics_10_1200 = calculate_avg_precision_recall_for_category(politics_docs, 10, 1200)\n",
    "politics_precision_avg_10_1200 = politics_10_1200[0]\n",
    "politics_recall_avg_10_1200 = politics_10_1200[1]\n",
    "row9.append(politics_precision_avg_10_1200)\n",
    "row9.append(politics_recall_avg_10_1200)\n",
    "\n",
    "sport_docs = list(filter(lambda d: d.category == \"sport\", documents))\n",
    "sport_6_800 = calculate_avg_precision_recall_for_category(sport_docs, 6, 800)\n",
    "sport_precision_avg_6_800 = sport_6_800[0]\n",
    "sport_recall_avg_6_800 = sport_6_800[1]\n",
    "row1.append(sport_precision_avg_6_800)\n",
    "row1.append(sport_precision_avg_6_800)\n",
    "\n",
    "sport_6_1010 = calculate_avg_precision_recall_for_category(sport_docs, 6, 1010)\n",
    "sport_precision_avg_6_1010 = sport_6_1010[0]\n",
    "sport_recall_avg_6_1010 = sport_6_1010[1]\n",
    "row2.append(sport_precision_avg_6_1010)\n",
    "row2.append(sport_recall_avg_6_1010)\n",
    "\n",
    "sport_6_1200 = calculate_avg_precision_recall_for_category(sport_docs, 6, 1200)\n",
    "sport_precision_avg_6_1200 = sport_6_1200[0]\n",
    "sport_recall_avg_6_1200 = sport_6_1200[1]\n",
    "row3.append(sport_precision_avg_6_1200)\n",
    "row3.append(sport_recall_avg_6_1200)\n",
    "\n",
    "sport_8_800 = calculate_avg_precision_recall_for_category(sport_docs, 8, 800)\n",
    "sport_precision_avg_8_800 = sport_8_800[0]\n",
    "sport_recall_avg_8_800 = sport_8_800[1]\n",
    "row4.append(sport_precision_avg_8_800)\n",
    "row4.append(sport_recall_avg_8_800)\n",
    "\n",
    "sport_8_1010 = calculate_avg_precision_recall_for_category(sport_docs, 8, 1010)\n",
    "sport_precision_avg_8_1010 = sport_8_1010[0]\n",
    "sport_recall_avg_8_1010 = sport_8_1010[1]\n",
    "row5.append(sport_precision_avg_8_1010)\n",
    "row5.append(sport_recall_avg_8_1010)\n",
    "\n",
    "sport_8_1200 = calculate_avg_precision_recall_for_category(sport_docs, 8, 1200)\n",
    "sport_precision_avg_8_1200 = sport_8_1200[0]\n",
    "sport_recall_avg_8_1200 = sport_8_1200[1]\n",
    "row6.append(sport_precision_avg_8_1200)\n",
    "row6.append(sport_recall_avg_8_1200)\n",
    "\n",
    "sport_10_800 = calculate_avg_precision_recall_for_category(sport_docs, 10, 800)\n",
    "sport_precision_avg_10_800 = sport_10_800[0]\n",
    "sport_recall_avg_10_800 = sport_10_800[1]\n",
    "row7.append(sport_precision_avg_10_800)\n",
    "row7.append(sport_recall_avg_10_800)\n",
    "\n",
    "sport_10_1010 = calculate_avg_precision_recall_for_category(sport_docs, 10, 1010)\n",
    "sport_precision_avg_10_1010 = sport_10_1010[0]\n",
    "sport_recall_avg_10_1010 = sport_10_1010[1]\n",
    "row8.append(sport_precision_avg_10_1010)\n",
    "row8.append(sport_recall_avg_10_1010)\n",
    "\n",
    "sport_10_1200 = calculate_avg_precision_recall_for_category(sport_docs, 10, 1200)\n",
    "sport_precision_avg_10_1200 = sport_10_1200[0]\n",
    "sport_recall_avg_10_1200 = sport_10_1200[1]\n",
    "row9.append(sport_precision_avg_10_1200)\n",
    "row9.append(sport_recall_avg_10_1200)\n",
    "\n",
    "\n",
    "tech_docs = list(filter(lambda d: d.category == \"tech\", documents))\n",
    "tech_6_800 = calculate_avg_precision_recall_for_category(tech_docs, 6, 800)\n",
    "tech_precision_avg_6_800 = tech_6_800[0]\n",
    "tech_recall_avg_6_800 = tech_6_800[1]\n",
    "row1.append(tech_precision_avg_6_800)\n",
    "row1.append(tech_precision_avg_6_800)\n",
    "\n",
    "tech_6_1010 = calculate_avg_precision_recall_for_category(tech_docs, 6, 1010)\n",
    "tech_precision_avg_6_1010 = tech_6_1010[0]\n",
    "tech_recall_avg_6_1010 = tech_6_1010[1]\n",
    "row2.append(tech_precision_avg_6_1010)\n",
    "row2.append(tech_recall_avg_6_1010)\n",
    "\n",
    "tech_6_1200 = calculate_avg_precision_recall_for_category(tech_docs, 6, 1200)\n",
    "tech_precision_avg_6_1200 = tech_6_1200[0]\n",
    "tech_recall_avg_6_1200 = tech_6_1200[1]\n",
    "row3.append(tech_precision_avg_6_1200)\n",
    "row3.append(tech_recall_avg_6_1200)\n",
    "\n",
    "tech_8_800 = calculate_avg_precision_recall_for_category(tech_docs, 8, 800)\n",
    "tech_precision_avg_8_800 = tech_8_800[0]\n",
    "tech_recall_avg_8_800 = tech_8_800[1]\n",
    "row4.append(tech_precision_avg_8_800)\n",
    "row4.append(tech_recall_avg_8_800)\n",
    "\n",
    "tech_8_1010 = calculate_avg_precision_recall_for_category(tech_docs, 8, 1010)\n",
    "tech_precision_avg_8_1010 = tech_8_1010[0]\n",
    "tech_recall_avg_8_1010 = tech_8_1010[1]\n",
    "row5.append(tech_precision_avg_8_1010)\n",
    "row5.append(tech_recall_avg_8_1010)\n",
    "\n",
    "tech_8_1200 = calculate_avg_precision_recall_for_category(tech_docs, 8, 1200)\n",
    "tech_precision_avg_8_1200 = tech_8_1200[0]\n",
    "tech_recall_avg_8_1200 = tech_8_1200[1]\n",
    "row6.append(tech_precision_avg_8_1200)\n",
    "row6.append(tech_recall_avg_8_1200)\n",
    "\n",
    "tech_10_800 = calculate_avg_precision_recall_for_category(tech_docs, 10, 800)\n",
    "tech_precision_avg_10_800 = tech_10_800[0]\n",
    "tech_recall_avg_10_800 = tech_10_800[1]\n",
    "row7.append(tech_precision_avg_10_800)\n",
    "row7.append(tech_recall_avg_10_800)\n",
    "\n",
    "tech_10_1010 = calculate_avg_precision_recall_for_category(tech_docs, 10, 1010)\n",
    "tech_precision_avg_10_1010 = tech_10_1010[0]\n",
    "tech_recall_avg_10_1010 = tech_10_1010[1]\n",
    "row8.append(tech_precision_avg_10_1010)\n",
    "row8.append(tech_recall_avg_10_1010)\n",
    "\n",
    "tech_10_1200 = calculate_avg_precision_recall_for_category(tech_docs, 10, 1200)\n",
    "tech_precision_avg_10_1200 = tech_10_1200[0]\n",
    "tech_recall_avg_10_1200 = tech_10_1200[1]\n",
    "row9.append(tech_precision_avg_10_1200)\n",
    "row9.append(tech_recall_avg_10_1200)\n",
    "\n",
    "\n",
    "header = [\"p\", \"l\", \"all_docs_precision\", \"all_docs_recall\", \"business_precision\", \"business_recall\",\"entertainment_precision\", \"entertainment_recall\",\"politics_precision\", \"politics_recall\",\"sport_precision\", \"sport_recall\",\"tech_precision\", \"tech_recall\"]\n",
    "data = [row1, row2, row3, row4, row5, row6, row7, row8, row9]\n",
    "write_to_csv('precision_recall.csv', header, data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**...** (additional questions with empirical results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>END</H3>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
